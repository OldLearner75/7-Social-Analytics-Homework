{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "#Base code from 01-Lesson-Plans/07-Social-Analytics/3/Activities/02-Stu_Recap_Tweet_Analysis/Solved/BreakingNews.ipynb\n",
    "#this project is the same as the exercise above except we need to loop through 5 news organizations\n",
    "#and pull 100 from each instead of 25 then do a few charts from the data...should be easy...hahaha...famous last words\n",
    "#running out of time...turning this in...\n",
    "\n",
    "\n",
    "#Your final Jupyter notebook must:\n",
    "\n",
    "#* Pull last 100 tweets from each outlet.\n",
    "#* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet.\n",
    "#* Pull into a DataFrame the tweet's source account, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "#* Export the data in the DataFrame into a CSV file.\n",
    "#* Save PNG images for each plot.\n",
    "\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Target Search Term\n",
    "counter = 1\n",
    "target_term =[\"BBCWorld\", \"CBSNews\", \"CNN\", \"FoxNews\", \"nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Lists to hold sentiments\n",
    "df_info = {\n",
    "    \"compound_list\": [],\n",
    "    \"positive_list\": [],\n",
    "    \"negative_list\": [],\n",
    "    \"neutral_list\": [],\n",
    "    \"source\": [],\n",
    "    \"content\": [],\n",
    "    \"date\": [],\n",
    "    \"tweets_ago\": []}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Need 100 from each\n",
    "    \n",
    "\n",
    "    \n",
    "for term in target_term:\n",
    "    public_tweets = api.search(term, count=100, result_type=\"recent\")\n",
    "    \n",
    "    for tweet in public_tweets[\"statuses\"]:\n",
    "\n",
    "    # Run Vader Analysis on each tweet\n",
    "        compound = analyzer.polarity_scores(tweet[\"text\"])[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(tweet[\"text\"])[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(tweet[\"text\"])[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(tweet[\"text\"])[\"neg\"]\n",
    "\n",
    "    # Add each value to the appropriate array\n",
    "        df_info[\"compound_list\"].append(compound)\n",
    "        df_info[\"positive_list\"].append(pos)\n",
    "        df_info[\"negative_list\"].append(neg)\n",
    "        df_info[\"neutral_list\"].append(neu)\n",
    "    \n",
    "        df_info[\"source\"].append(tweet[\"user\"][\"name\"])\n",
    "        df_info[\"content\"].append(tweet[\"text\"])\n",
    "        df_info[\"date\"].append(tweet[\"created_at\"])\n",
    "        df_info[\"tweets_ago\"].append(counter)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hideCode": true
   },
   "outputs": [],
   "source": [
    "# Store the Average Sentiments\n",
    "sentiment = {\"Compound\": np.mean(compound_list),\n",
    "             \"Positive\": np.mean(positive_list),\n",
    "             \"Neutral\": np.mean(negative_list),\n",
    "             \"Negative\": np.mean(neutral_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hideCode": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Compound': 0.03430965794768611, 'Positive': 0.07817706237424547, 'Neutral': 0.06906841046277666, 'Negative': 0.8527746478873239}\n"
     ]
    }
   ],
   "source": [
    "# Print the Sentiments\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>compound_list</th>\n",
       "      <th>positive_list</th>\n",
       "      <th>neutral_list</th>\n",
       "      <th>negative_listtweets_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senso Di Nausea</td>\n",
       "      <td>RT @Atlantide4world: #Sudan:le proteste contro...</td>\n",
       "      <td>Sun Jan 20 01:05:13 +0000 2019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Glare</td>\n",
       "      <td>@BBCWorld Hey @ComfortablySmug</td>\n",
       "      <td>Sun Jan 20 01:05:07 +0000 2019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kyle Scanlon lost his soul in Portland Oregon</td>\n",
       "      <td>RT @ProgressNow00: @BBCWorld Racism is taught....</td>\n",
       "      <td>Sun Jan 20 01:05:02 +0000 2019</td>\n",
       "      <td>-0.9274</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.523</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Danny R. Stewart</td>\n",
       "      <td>@Demalonzo @BBCWorld Put this kids name around...</td>\n",
       "      <td>Sun Jan 20 01:05:00 +0000 2019</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.753</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clarisse L. Hodgkins</td>\n",
       "      <td>@BBCWorld Those taunting teens are a disgrace ...</td>\n",
       "      <td>Sun Jan 20 01:04:58 +0000 2019</td>\n",
       "      <td>-0.7123</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source  \\\n",
       "0                                Senso Di Nausea   \n",
       "1                                      The Glare   \n",
       "2  Kyle Scanlon lost his soul in Portland Oregon   \n",
       "3                               Danny R. Stewart   \n",
       "4                           Clarisse L. Hodgkins   \n",
       "\n",
       "                                             content  \\\n",
       "0  RT @Atlantide4world: #Sudan:le proteste contro...   \n",
       "1                     @BBCWorld Hey @ComfortablySmug   \n",
       "2  RT @ProgressNow00: @BBCWorld Racism is taught....   \n",
       "3  @Demalonzo @BBCWorld Put this kids name around...   \n",
       "4  @BBCWorld Those taunting teens are a disgrace ...   \n",
       "\n",
       "                             date  compound_list  positive_list  neutral_list  \\\n",
       "0  Sun Jan 20 01:05:13 +0000 2019         0.0000          0.000         1.000   \n",
       "1  Sun Jan 20 01:05:07 +0000 2019         0.0000          0.000         1.000   \n",
       "2  Sun Jan 20 01:05:02 +0000 2019        -0.9274          0.000         0.523   \n",
       "3  Sun Jan 20 01:05:00 +0000 2019         0.8341          0.247         0.753   \n",
       "4  Sun Jan 20 01:04:58 +0000 2019        -0.7123          0.073         0.643   \n",
       "\n",
       "  negative_listtweets_ago  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(df_info, columns=[\"source\", \n",
    "                                             \"content\", \n",
    "                                             \"date\",\n",
    "                                             \"compound_list\",\n",
    "                                             \"positive_list\",\n",
    "                                             \"neutral_list\",\n",
    "                                             \"negative_list\"\n",
    "                                               \"tweets_ago\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is like http://localhost:8889/notebooks/01-Lesson-Plans/07-Social-Analytics/2/Activities/\n",
    "#08-Stu_Plot_Sentiments/Solved/Stu_Plot_Sentiments.ipynb\n",
    "# Create plot\n",
    "x_vals = df[\"Tweets Ago\"]\n",
    "y_vals = sentiments_pd[\"Compound\"]\n",
    "plt.plot(x_vals,\n",
    "         y_vals, marker=\"o\", linewidth=0.5,\n",
    "         alpha=0.8)\n",
    "\n",
    "# # Incorporate the other graph properties\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d %H:%M\")\n",
    "plt.title(f\"Sentiment Analysis of Tweets ({now}) for {target_user}\")\n",
    "plt.xlim([x_vals.max(),x_vals.min()]) #Bonus\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
